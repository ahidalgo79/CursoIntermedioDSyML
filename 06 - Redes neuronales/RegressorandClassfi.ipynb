{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-xOaeWDssVW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data=pd.read_csv(\"https://gist.githubusercontent.com/javierIA/651810e8710cf37c5533aba164d18aa8/raw/68ad93a282f8dc92bc933284a645e9d6b301c6c4/data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Iris dataset\n",
        "X=data['reading score'].values\n",
        "Y=data['writing score'].values\n",
        "X=X.reshape(-1,1)\n",
        "\n",
        "# One hot encode target values\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse_test = model.evaluate(X_test, X_test)\n",
        "print(f'Mean Squared Error on test set: {mse_test}')\n",
        "\n",
        "# Realizar predicciones\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Visualizar los resultados\n",
        "plt.scatter(X_test, X_test, color='black', label='Real data')\n",
        "plt.plot(X_test, Y_pred, color='blue', linewidth=3, label='Regression line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "msT5J3m1s1w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"https://gist.githubusercontent.com/javierIA/52184893d57d9a644e2362ee108cfa9e/raw/7297193ea28a0ebed89cb230034a0e62043fe288/bills.csv\")"
      ],
      "metadata": {
        "id": "uuFIzGKLuxJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x=np.array(bills.drop([\"Unnamed: 0\",\"is_genuine\"],axis=1))\n",
        "x"
      ],
      "metadata": {
        "id": "tQ6gcVJQu5gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(bills[\"is_genuine\"])\n",
        "y\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n"
      ],
      "metadata": {
        "id": "eZWV9inUu_yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar los datos\n",
        "df=pd.read_csv(\"https://gist.githubusercontent.com/javierIA/52184893d57d9a644e2362ee108cfa9e/raw/7297193ea28a0ebed89cb230034a0e62043fe288/bills.csv\")\n",
        "# Dividir los datos en caracter√≠sticas (X) y etiquetas (y)\n",
        "X =np.array(df.drop([\"Unnamed: 0\",\"is_genuine\"],axis=1))\n",
        "\n",
        "y = df['is_genuine']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Crear el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.1)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "metadata": {
        "id": "nHW3ZWJMvkto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Estandarizar los datos\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(1024, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "\n",
        "# Estandarizar los datos\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(1024, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "3JTtP4SiwQfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# One hot encode target values\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "y = enc.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build a neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=(4,), activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=5)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "Q9oO6qKaxCM_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}